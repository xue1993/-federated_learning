{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "utils.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOF6O4BB0QqPJQIxRlSiv8H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xue1993/-federated_learning/blob/master/code/utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zjAvULb5eBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "# Python version: 3.6\n",
        "\n",
        "import os\n",
        "import copy\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from sampling import mnist_iid, mnist_noniid, mnist_noniid_unequal\n",
        "from sampling import cifar_iid, cifar_noniid\n",
        "\n",
        "\n",
        "def get_dataset(args):\n",
        "    \"\"\" Returns train and test datasets and a user group which is a dict where\n",
        "    the keys are the user index and the values are the corresponding data for\n",
        "    each of those users.\n",
        "    \"\"\"\n",
        "\n",
        "    if args.dataset == 'cifar':\n",
        "        data_dir = './data/cifar/'\n",
        "        \n",
        "        if not os.path.exists(data_dir):\n",
        "            os.makedirs(data_dir)\n",
        "        \n",
        "        apply_transform = transforms.Compose(\n",
        "            [transforms.ToTensor(),\n",
        "             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "        train_dataset = datasets.MNIST(data_dir, train=True, download=True,\n",
        "                                       transform=apply_transform)\n",
        "\n",
        "        test_dataset = datasets.MNIST(data_dir, train=False, download=True,\n",
        "                                      transform=apply_transform)\n",
        "\n",
        "        # sample training data amongst users\n",
        "        if args.iid:\n",
        "            # Sample IID user data from Mnist\n",
        "            user_groups = cifar_iid(train_dataset, args.num_users)\n",
        "        else:\n",
        "            # Sample Non-IID user data from Mnist\n",
        "            if args.unequal:\n",
        "                # Chose uneuqal splits for every user\n",
        "                raise NotImplementedError()\n",
        "            else:\n",
        "                # Chose euqal splits for every user\n",
        "                user_groups = cifar_noniid(train_dataset, args.num_users)\n",
        "\n",
        "    elif args.dataset == 'mnist' or 'fmnist':\n",
        "        if args.dataset == 'mnist':\n",
        "            data_dir = './data/mnist/'\n",
        "        else:\n",
        "            data_dir = './data/fmnist/'\n",
        "            \n",
        "        if not os.path.exists(data_dir):\n",
        "            os.makedirs(data_dir)    \n",
        "\n",
        "        apply_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "        train_dataset = datasets.MNIST(data_dir, train=True, download=True,\n",
        "                                       transform=apply_transform)\n",
        "\n",
        "        test_dataset = datasets.MNIST(data_dir, train=False, download=True,\n",
        "                                      transform=apply_transform)\n",
        "\n",
        "        # sample training data amongst users\n",
        "        if args.iid:\n",
        "            # Sample IID user data from Mnist\n",
        "            user_groups = mnist_iid(train_dataset, args.num_users)\n",
        "        else:\n",
        "            # Sample Non-IID user data from Mnist\n",
        "            if args.unequal:\n",
        "                # Chose uneuqal splits for every user\n",
        "                user_groups = mnist_noniid_unequal(train_dataset, args.num_users)\n",
        "            else:\n",
        "                # Chose euqal splits for every user\n",
        "                user_groups = mnist_noniid(train_dataset, args.num_users)\n",
        "\n",
        "    return train_dataset, test_dataset, user_groups\n",
        "\n",
        "\n",
        "def average_weights(w):\n",
        "    \"\"\"\n",
        "    Returns the average of the weights.\n",
        "    \"\"\"\n",
        "    w_avg = copy.deepcopy(w[0])\n",
        "    for key in w_avg.keys():\n",
        "        for i in range(1, len(w)):\n",
        "            w_avg[key] += w[i][key]\n",
        "        w_avg[key] = torch.div(w_avg[key], len(w))\n",
        "    return w_avg\n",
        "\n",
        "\n",
        "def exp_details(args):\n",
        "    print('\\nExperimental details:')\n",
        "    print(f'    Model     : {args.model}')\n",
        "    print(f'    Optimizer : {args.optimizer}')\n",
        "    print(f'    Learning  : {args.lr}')\n",
        "    print(f'    Global Rounds   : {args.epochs}\\n')\n",
        "    print(f'    Sparsityrate    : {args.spr}\\n')\n",
        "\n",
        "    print('    Federated parameters:')\n",
        "    if args.iid:\n",
        "        print('    IID')\n",
        "    else:\n",
        "        print('    Non-IID')\n",
        "    print(f'    Fraction of users  : {args.frac}')\n",
        "    print(f'    Local Batch size   : {args.local_bs}')\n",
        "    print(f'    Local Epochs       : {args.local_ep}\\n')\n",
        "    return\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}