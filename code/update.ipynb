{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "update.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOJv7me9MCXqipT0a7NeFF7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xue1993/-federated_learning/blob/master/code/update.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF3-9dyH5tfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "# Python version: 3.6\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class DatasetSplit(Dataset):\n",
        "    \"\"\"An abstract Dataset class wrapped around Pytorch Dataset class.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset, idxs):\n",
        "        self.dataset = dataset\n",
        "        self.idxs = [int(i) for i in idxs]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idxs)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        image, label = self.dataset[self.idxs[item]]\n",
        "        return torch.tensor(image), torch.tensor(label)\n",
        "\n",
        "\n",
        "class LocalUpdate(object):\n",
        "    def __init__(self, args, dataset, idxs, logger):\n",
        "        self.args = args\n",
        "        self.logger = logger\n",
        "        self.trainloader, self.validloader, self.testloader = self.train_val_test(\n",
        "            dataset, list(idxs))\n",
        "        self.device = 'cuda' if args.gpu else 'cpu'\n",
        "        # Default criterion set to NLL loss function\n",
        "        self.criterion = nn.NLLLoss().to(self.device)\n",
        "\n",
        "    def train_val_test(self, dataset, idxs):\n",
        "        \"\"\"\n",
        "        Returns train, validation and test dataloaders for a given dataset\n",
        "        and user indexes.\n",
        "        \"\"\"\n",
        "        # split indexes for train, validation, and test (80, 10, 10)\n",
        "        idxs_train = idxs[:int(0.8*len(idxs))]\n",
        "        idxs_val = idxs[int(0.8*len(idxs)):int(0.9*len(idxs))]\n",
        "        idxs_test = idxs[int(0.9*len(idxs)):]\n",
        "\n",
        "        trainloader = DataLoader(DatasetSplit(dataset, idxs_train),\n",
        "                                 batch_size=self.args.local_bs, shuffle=True)\n",
        "        validloader = DataLoader(DatasetSplit(dataset, idxs_val),\n",
        "                                 batch_size=int(len(idxs_val)/10), shuffle=False)\n",
        "        testloader = DataLoader(DatasetSplit(dataset, idxs_test),\n",
        "                                batch_size=int(len(idxs_test)/10), shuffle=False)\n",
        "        return trainloader, validloader, testloader\n",
        "\n",
        "    def update_weights(self, model, global_round):\n",
        "        # Set mode to train model\n",
        "        model.train()\n",
        "        epoch_loss = []\n",
        "\n",
        "        # Set optimizer for the local updates\n",
        "        if self.args.optimizer == 'sgd':\n",
        "            optimizer = torch.optim.SGD(model.parameters(), lr=self.args.lr,\n",
        "                                        momentum=0.5)\n",
        "        elif self.args.optimizer == 'adam':\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=self.args.lr,\n",
        "                                         weight_decay=1e-4)\n",
        "\n",
        "        for iter in range(self.args.local_ep):\n",
        "            batch_loss = []\n",
        "            for batch_idx, (images, labels) in enumerate(self.trainloader):\n",
        "                images, labels = images.to(self.device), labels.to(self.device)\n",
        "\n",
        "                model.zero_grad()\n",
        "                log_probs = model(images)\n",
        "                loss = self.criterion(log_probs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                #if self.args.verbose and (batch_idx % 10 == 0):\n",
        "                #    print('| Global Round : {} | Local Epoch : {} | [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                #        global_round, iter, batch_idx * len(images),\n",
        "                #        len(self.trainloader.dataset),\n",
        "                #print('fx')\n",
        "                #        100. * batch_idx / len(self.trainloader), loss.item()))\n",
        "                self.logger.add_scalar('loss', loss.item())\n",
        "                batch_loss.append(loss.item())\n",
        "            epoch_loss.append(sum(batch_loss)/len(batch_loss))\n",
        "\n",
        "        return model.state_dict(), sum(epoch_loss) / len(epoch_loss)\n",
        "\n",
        "    def inference(self, model):\n",
        "        \"\"\" Returns the inference accuracy and loss.\n",
        "        \"\"\"\n",
        "\n",
        "        model.eval()\n",
        "        loss, total, correct = 0.0, 0.0, 0.0\n",
        "\n",
        "        for batch_idx, (images, labels) in enumerate(self.testloader):\n",
        "            images, labels = images.to(self.device), labels.to(self.device)\n",
        "\n",
        "            # Inference\n",
        "            outputs = model(images)\n",
        "            batch_loss = self.criterion(outputs, labels)\n",
        "            loss += batch_loss.item()\n",
        "\n",
        "            # Prediction\n",
        "            _, pred_labels = torch.max(outputs, 1)\n",
        "            pred_labels = pred_labels.view(-1)\n",
        "            correct += torch.sum(torch.eq(pred_labels, labels)).item()\n",
        "            total += len(labels)\n",
        "\n",
        "        accuracy = correct/total\n",
        "        return accuracy, loss\n",
        "\n",
        "\n",
        "def test_inference(args, model, test_dataset):\n",
        "    \"\"\" Returns the test accuracy and loss.\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    loss, total, correct = 0.0, 0.0, 0.0\n",
        "\n",
        "    device = 'cuda' if args.gpu else 'cpu'\n",
        "    criterion = nn.NLLLoss().to(device)\n",
        "    testloader = DataLoader(test_dataset, batch_size=128,\n",
        "                            shuffle=False)\n",
        "\n",
        "    for batch_idx, (images, labels) in enumerate(testloader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Inference\n",
        "        outputs = model(images)\n",
        "        batch_loss = criterion(outputs, labels)\n",
        "        loss += batch_loss.item()\n",
        "\n",
        "        # Prediction\n",
        "        _, pred_labels = torch.max(outputs, 1)\n",
        "        pred_labels = pred_labels.view(-1)\n",
        "        correct += torch.sum(torch.eq(pred_labels, labels)).item()\n",
        "        total += len(labels)\n",
        "\n",
        "    accuracy = correct/total\n",
        "    return accuracy, loss\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}